{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize these weights in NumPy, we have to provide the shape of the matrix. \n",
    "If features is a 2D array containing the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of records and input units\n",
    "n_records, n_inputs = features.shape\n",
    "\n",
    "# Number of hidden units\n",
    "n_hidden = 2\n",
    "weights_input_to_hidden = np.random.normal(0, n_inputs**-0.5, size=(n_inputs, n_hidden))"
   ]
  },
  {
   "attachments": {
    "hidden-layer-weights.gif": {
     "image/gif": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This creates a 2D array (i.e. a matrix) named weights_input_to_hidden with dimensions n_inputs by n_hidden. \n",
    "Remember how the input to a hidden unit is the sum of all the inputs multiplied by the hidden unit's weights. \n",
    "So for each hidden layer unit, hj we need to calculate the following:\n",
    "    ![hidden-layer-weights.gif](attachment:hidden-layer-weights.gif)\n",
    "    \n",
    "For this part though, you'll only need to know how to multiply a matrix with a vector.\n",
    "\n",
    "In this case, we're multiplying the inputs (a row vector here) by the weights. To do this, you take the dot (inner) product of the inputs with each column in the weights matrix. For example, to calculate the input to the first hidden unit, j = 1j=1, you'd take the dot product of the inputs with the first column of the weights matrix.\n",
    "\n",
    "h1 = x1w11 + x1w21 + x1w31\n",
    "\n",
    "And for the second hidden layer input, you calculate the dot product of the inputs with the second column. And so on and so forth.\n",
    "\n",
    "In NumPy, you can do this for all the inputs and all the outputs at once using np.dot\n",
    "hidden_inputs = np.dot(inputs, weights_input_to_hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing with matrix multiplication is that the dimensions match. \n",
    "For matrix multiplication to work, there has to be the same number of elements in the dot products. In the first example, there are three columns in the input vector, and three rows in the weights matrix. In the second example, there are three columns in the weights matrix and three rows in the input vector. \n",
    "If the dimensions don't match, you'll get this:\n",
    "\n",
    "#Same weights and features as above, but swapped the order\n",
    "hidden_inputs = np.dot(weights_input_to_hidden, features)\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "<ipython-input-11-1bfa0f615c45> in <module>()\n",
    "----> 1 hidden_in = np.dot(weights_input_to_hidden, X)\n",
    "\n",
    "ValueError: shapes (3,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)\n",
    "\n",
    "\n",
    "The dot product can't be computed for a 3x2 matrix and 3-element array. That's because the 2 columns in the matrix don't match the number of elements in the array. \n",
    "The rule is that if you're multiplying an array from the left, the array must have the same number of elements as there are rows in the matrix. And if you're multiplying the matrix from the left, the number of columns in the matrix must equal the number of elements in the array on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a column vector\n",
    "\n",
    "You see above that sometimes you'll want a column vector, even though by default NumPy arrays work like row vectors. It's possible to get the transpose of an array like so arr.T, but for a 1D array, the transpose will return a row vector. Instead, use arr[:,None] to create a column vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(features)\n",
    "> array([ 0.49671415, -0.1382643 ,  0.64768854])\n",
    "\n",
    "print(features.T)\n",
    "> array([ 0.49671415, -0.1382643 ,  0.64768854])\n",
    "\n",
    "print(features[:, None])\n",
    "> array([[ 0.49671415],\n",
    "       [-0.1382643 ],\n",
    "       [ 0.64768854]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can create arrays with two dimensions. Then, you can use arr.T to get the column vector.\n",
    "\n",
    "np.array(features, ndmin=2)\n",
    "> array([[ 0.49671415, -0.1382643 ,  0.64768854]])\n",
    "\n",
    "np.array(features, ndmin=2).T\n",
    "> array([[ 0.49671415],\n",
    "       [-0.1382643 ],\n",
    "       [ 0.64768854]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming quiz\n",
    "Below, you'll implement a forward pass through a 4x3x2 network, with sigmoid activation functions for both layers.\n",
    "\n",
    "Things to do:\n",
    "\n",
    "Calculate the input to the hidden layer.\n",
    "Calculate the hidden layer output.\n",
    "Calculate the input to the output layer.\n",
    "Calculate the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[0.41492192 0.42604313 0.5002434 ]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make a forward pass through the network\n",
    "\n",
    "hidden_layer_in = np.dot(X,weights_input_to_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output-layer Output:\n",
      "[0.49815196 0.48539772]\n"
     ]
    }
   ],
   "source": [
    "output_layer_in = np.dot(hidden_layer_out,weights_hidden_to_output )\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
